---
layout: single
title: "ìºê¸€ íƒ€ì´íƒ€ë‹‰"
author_profile: true
read_time: true
toc: true
toc_sticky: true
---
<br>

# ì„¤ëª…

| í•­ëª©           | ì„¤ëª… |
|----------------|------|
| ì œëª©      | Titanic : Machine Learning from Disaster |
| ëª©í‘œ      | ìºê¸€ ì…ë¬¸ ëŒ€íšŒì¸ íƒ€ì´íƒ€ë‹‰ ìƒì¡´ ì˜ˆì¸¡ ì°¸ê°€ |
| ì°¸ê³       | [`test.csv` ìŠ¹ê°ë“¤ì˜ ìƒì¡´ ì—¬ë¶€ ì˜ˆì¸¡ (`submission.csv`)](https://cyc1am3n.github.io/2018/10/09/my-first-kaggle-competition_titanic.html) |

<br>

# í”„ë¡œì íŠ¸ ìš”ì•½

| í•­ëª©           | ì„¤ëª… |
|----------------|------|
| ì½”ë“œ ëª©ì       | Titanic ë°ì´í„°ë¡œ ìƒì¡´ ì˜ˆì¸¡ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ë§Œë“¤ê¸° |
| ìµœì¢… ê²°ê³¼      | `test.csv` ìŠ¹ê°ë“¤ì˜ ìƒì¡´ ì—¬ë¶€ ì˜ˆì¸¡ (`submission.csv`) |
| ëª¨ë¸ ì„±ëŠ¥ í‰ê°€ | í›ˆë ¨ ë°ì´í„°ì— ëŒ€í•œ ë‚´ë¶€ ì •í™•ë„ ì¶œë ¥ |

<br>

# ëª¨ë¸ë³„ ì •í™•ë„ (í›ˆë ¨ ë°ì´í„° ê¸°ì¤€)

| ëª¨ë¸ | ì •í™•ë„ |
|------|--------|
| Logistic Regression | 83.05 % |
| SVM                  | 83.39 % |
| K-Nearest Neighbors  | 85.07 % |
| Random Forest        | 87.88 % |
| Naive Bayes          | 79.24 % |

<br>

# ìºê¸€ ì œì¶œ


<img src="https://teitow.github.io/kagglekeggla/assets/images/kaggle-titanic1.png"
     alt="íƒ€ì´íƒ€ë‹‰ ê²°ê³¼ 1"
     style="border: 2px solid #444; border-radius: 6px; display: block; margin-bottom: 20px;">

<img src="https://teitow.github.io/kagglekeggla/assets/images/kaggle-titanic2.png"
     alt="íƒ€ì´íƒ€ë‹‰ ê²°ê³¼ 2"
     style="border: 2px solid #444; border-radius: 6px; display: block;">


<br>

#  ì „ì²´ ì½”ë“œ

{% highlight python %}
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
%matplotlib inline

from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.naive_bayes import GaussianNB
from sklearn.utils import shuffle

import seaborn as sns
sns.set() 

train = pd.read_csv('/kaggle/input/titanic/train.csv')
test = pd.read_csv('/kaggle/input/titanic/test.csv')
train_and_test = [train, test]

for dataset in train_and_test:
    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\.')
    dataset['Title'] = dataset['Title'].replace(['Capt', 'Col', 'Countess', 'Don','Dona', 'Dr', 'Jonkheer',
                                                 'Lady','Major', 'Rev', 'Sir'], 'Other')
    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')
    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')
    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')
    dataset['Title'] = dataset['Title'].astype(str)

for dataset in train_and_test:
    dataset['Sex'] = dataset['Sex'].astype(str)

for dataset in train_and_test:
    dataset['Embarked'] = dataset['Embarked'].fillna('S')
    dataset['Embarked'] = dataset['Embarked'].astype(str)

for dataset in train_and_test:
    dataset['Age'].fillna(dataset['Age'].mean(), inplace=True)
    dataset['Age'] = dataset['Age'].astype(int)

    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0
    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1
    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2
    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3
    dataset.loc[ dataset['Age'] > 64, 'Age'] = 4

    dataset['Age'] = dataset['Age'].map({ 0: 'Child', 1: 'Young', 2: 'Middle', 3: 'Prime', 4: 'Old' }).astype(str)

for dataset in train_and_test:
    dataset['Fare'] = dataset['Fare'].fillna(13.675) 
    dataset.loc[ dataset['Fare'] <= 8, 'Fare'] = 0
    dataset.loc[(dataset['Fare'] > 8) & (dataset['Fare'] <= 14), 'Fare'] = 1
    dataset.loc[(dataset['Fare'] > 14) & (dataset['Fare'] <= 31), 'Fare'] = 2
    dataset.loc[(dataset['Fare'] > 31) & (dataset['Fare'] <= 50), 'Fare'] = 3
    dataset.loc[ dataset['Fare'] > 50, 'Fare'] = 4
    dataset['Fare'] = dataset['Fare'].astype(int)

for dataset in train_and_test:
    dataset['Family'] = dataset['SibSp'] + dataset['Parch']
    dataset.loc[dataset['Family'] == 0, 'Family'] = 0
    dataset.loc[(dataset['Family'] >= 1) & (dataset['Family'] <= 2), 'Family'] = 1
    dataset.loc[(dataset['Family'] >= 3) & (dataset['Family'] <= 4), 'Family'] = 2
    dataset.loc[dataset['Family'] >= 5, 'Family'] = 3
    dataset['Family'] = dataset['Family'].astype(int)

features_drop = ['Name', 'Ticket', 'Cabin', 'SibSp', 'Parch']
train = train.drop(features_drop, axis=1)
test = test.drop(features_drop, axis=1)
train = train.drop(['PassengerId'], axis=1)

train = pd.get_dummies(train)
test = pd.get_dummies(test)

train_label = train['Survived']
train_data = train.drop('Survived', axis=1)
test_data = test.drop("PassengerId", axis=1).copy()

train_data, train_label = shuffle(train_data, train_label, random_state=5)

def train_and_test(model):
    model.fit(train_data, train_label)
    prediction = model.predict(test_data)
    accuracy = round(model.score(train_data, train_label) * 100, 2)
    print("Accuracy:", accuracy, "%")
    return prediction

log_pred = train_and_test(LogisticRegression())
svm_pred = train_and_test(SVC())
knn_pred = train_and_test(KNeighborsClassifier(n_neighbors = 4))
rf_pred = train_and_test(RandomForestClassifier(n_estimators=100))
nb_pred = train_and_test(GaussianNB())

submission = pd.DataFrame({
    "PassengerId": test["PassengerId"],
    "Survived": rf_pred
})
submission.to_csv('submission_rf2.csv', index=False)
{% endhighlight %}


# [ğŸ“¥ ipynb íŒŒì¼ ë‹¤ìš´ë¡œë“œ](https://teitow.github.io/kagglekeggla/assets/files/titanic-machine-learning-from-disaster.ipynb)


